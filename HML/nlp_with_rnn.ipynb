{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTwQ5koXdB7m"
      },
      "source": [
        "### Char-RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "27x_dqlpdB7p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ay9UfRaRdB7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6025927e-c701-4ffe-abc0-83fdf0f62173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = keras.utils.get_file(\"shhakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1tx-_FsQdB7s"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9JOppQVdB7s",
        "outputId": "9d27d025-63f6-4315-8212-1699456f9145"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s4uzuhFdB7t",
        "outputId": "b503811b-b5c0-44ec-efb4-4fbf94808dc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z_oeDwOPdB7t"
      },
      "outputs": [],
      "source": [
        "max_id = len(tokenizer.word_index) # 고유 글자 개수\n",
        "dataset_size = tokenizer.document_count # 전체 글자 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k-6M3Od8dB7u"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "niCAWSdFdB7u"
      },
      "outputs": [],
      "source": [
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8pqnb-EPdB7u"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = 1글자 앞의 input\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M_qkq1OfdB7v"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SuXbKCDEdB7v"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpA6VUPVdB7v",
        "outputId": "517bec88-57f9-4ba4-d8e5-df054ced0b51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")\n",
        "\n",
        "dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be6THRwYdB7v",
        "outputId": "c36b8017-9e4e-480e-d1b8-c99df1e6feb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "31368/31368 [==============================] - 479s 15ms/step - loss: 1.6202\n",
            "Epoch 2/5\n",
            "31368/31368 [==============================] - 487s 15ms/step - loss: 1.5374\n",
            "Epoch 3/5\n",
            "31368/31368 [==============================] - 470s 15ms/step - loss: 1.5174\n",
            "Epoch 4/5\n",
            "31368/31368 [==============================] - 474s 15ms/step - loss: 1.5068\n",
            "Epoch 5/5\n",
            "31368/31368 [==============================] - 460s 15ms/step - loss: 1.5007\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gjtFJnPMdB7w"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        "  X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "  return tf.one_hot(X, max_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "60D_RL7bo54n",
        "outputId": "ea1b02b3-46e9-4066-db20-e127b998ee4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "YSKCzTrQpImW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "fs6O6D5NqnHe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"t\", temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMxFtil9rtBo",
        "outputId": "c43b178c-a7d5-4d93-de63-cc0fba5db9c8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to her to the maid:\n",
            "the matter for a scolding of a \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"w\", temperature=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyxtWp_7r9Oq",
        "outputId": "6f97e906-cedc-4f1a-db1f-818d2f04cff7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whares, or to the move is, no?\n",
            "\n",
            "but ano herpanio, g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"w\", temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbeMMd-JsU6U",
        "outputId": "c4953683-2166-4c75-9941-d14cbfac9ec9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w\n",
            "what sife.\n",
            "\n",
            "ged ah. stay ms y, world'd!\n",
            "whetiesio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZ3D9LbPsfk0"
      },
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}